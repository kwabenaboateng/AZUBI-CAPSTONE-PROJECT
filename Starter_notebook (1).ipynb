{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoZGjB_9Uiij"
   },
   "source": [
    "# IMPORTANT \n",
    "\n",
    "## Install latest version of packages to be used in the code\n",
    "\n",
    "The latest version of libraries need to be installed as per competition rules and kindly adhere to that and install the updated version of libraries in the code. \n",
    "\n",
    "## Please set random seed so that reproducible answers are attained\n",
    "\n",
    "Wherever randomness is expected, do select the random seed so that the results are reproducible. Reproducibility of results is a **very important** component of model development without which reliable models are not attained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Wjp74XdUQta",
    "outputId": "1b79eaab-cceb-4666-e85b-452a4a7010f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.25.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: catboost in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.6.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (5.14.1)\n",
      "Requirement already satisfied: six in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\kwabenaboateng\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn numpy pandas catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fYI4nuYZUw3C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from termcolor import colored\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('always') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbf9wqJGU20y"
   },
   "source": [
    "## Loading test and train datasets \n",
    "\n",
    "We will load the train and test datasets and do some basic level of EDA to understand the pattern of features in the data \n",
    "\n",
    "* <b> Train data: </b> This is the data which we will be using to train the model. Since we are solving a classification problem, we will have a column in train dataset corresponding to the target labels. \n",
    "* <b> Test data: </b> This is the data on which the predictions will be made based on the model trained on train dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "id": "Es4uUithU2QZ",
    "outputId": "79047a21-ef24-46b7-dba3-c6bbf3a4954d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThe shape of train data is    (89786, 0)     \u001b[0m\n",
      "\u001b[1m\u001b[32mThe shape of target column is (89786, 1)\u001b[0m\n",
      "\u001b[1m\u001b[34mThe shape of test data is     (89786, 41)      \u001b[0m\n",
      "------------------------------------------------------------------------------\n",
      "\u001b[32mThe train data looks like below :- \n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "\u001b[34mThe test data looks like below :- \n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>class</th>\n",
       "      <th>education_institute</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>is_hispanic</th>\n",
       "      <th>employment_commitment</th>\n",
       "      <th>unemployment_reason</th>\n",
       "      <th>...</th>\n",
       "      <th>country_of_birth_father</th>\n",
       "      <th>country_of_birth_mother</th>\n",
       "      <th>migration_code_change_in_msa</th>\n",
       "      <th>migration_prev_sunbelt</th>\n",
       "      <th>migration_code_move_within_reg</th>\n",
       "      <th>migration_code_change_in_reg</th>\n",
       "      <th>residence_1_year_ago</th>\n",
       "      <th>old_residence_reg</th>\n",
       "      <th>old_residence_state</th>\n",
       "      <th>importance_of_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>Same</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3388.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>5th or 6th grade</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>White</td>\n",
       "      <td>Central or South American</td>\n",
       "      <td>Full-time schedules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1177.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelors degree(BA AB BS)</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civilian spouse present</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Full-time schedules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4898.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Female</td>\n",
       "      <td>9th grade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Children or Armed Forces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>Same</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1391.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>9th grade</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>White</td>\n",
       "      <td>All other</td>\n",
       "      <td>Not in labor force</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   gender                    education     class education_institute  \\\n",
       "0   54     Male         High school graduate   Private                 NaN   \n",
       "1   53     Male             5th or 6th grade   Private                 NaN   \n",
       "2   42     Male   Bachelors degree(BA AB BS)   Private                 NaN   \n",
       "3   16   Female                    9th grade       NaN         High school   \n",
       "4   16     Male                    9th grade       NaN         High school   \n",
       "\n",
       "                     marital_status    race                 is_hispanic  \\\n",
       "0   Married-civilian spouse present   White                   All other   \n",
       "1   Married-civilian spouse present   White   Central or South American   \n",
       "2   Married-civilian spouse present   White                   All other   \n",
       "3                     Never married   White                   All other   \n",
       "4                     Never married   White                   All other   \n",
       "\n",
       "       employment_commitment unemployment_reason  ...  \\\n",
       "0   Children or Armed Forces                 NaN  ...   \n",
       "1        Full-time schedules                 NaN  ...   \n",
       "2        Full-time schedules                 NaN  ...   \n",
       "3   Children or Armed Forces                 NaN  ...   \n",
       "4         Not in labor force                 NaN  ...   \n",
       "\n",
       "   country_of_birth_father  country_of_birth_mother  \\\n",
       "0                       US                       US   \n",
       "1              El-Salvador              El-Salvador   \n",
       "2                       US                       US   \n",
       "3                       US                       US   \n",
       "4                       US                       US   \n",
       "\n",
       "  migration_code_change_in_msa  migration_prev_sunbelt  \\\n",
       "0                    unchanged                     NaN   \n",
       "1                            ?                       ?   \n",
       "2                            ?                       ?   \n",
       "3                    unchanged                     NaN   \n",
       "4                            ?                       ?   \n",
       "\n",
       "   migration_code_move_within_reg migration_code_change_in_reg  \\\n",
       "0                       unchanged                    unchanged   \n",
       "1                               ?                            ?   \n",
       "2                               ?                            ?   \n",
       "3                       unchanged                    unchanged   \n",
       "4                               ?                            ?   \n",
       "\n",
       "   residence_1_year_ago old_residence_reg  old_residence_state  \\\n",
       "0                  Same               NaN                  NaN   \n",
       "1                   NaN               NaN                  NaN   \n",
       "2                   NaN               NaN                  NaN   \n",
       "3                  Same               NaN                  NaN   \n",
       "4                   NaN               NaN                  NaN   \n",
       "\n",
       "  importance_of_record  \n",
       "0              3388.96  \n",
       "1              1177.55  \n",
       "2              4898.55  \n",
       "3              1391.44  \n",
       "4              1933.18  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################# Reading train and test datasets\n",
    "#train_data         = pd.read_csv('Train.csv')\n",
    "#test_data          = pd.read_csv('Test.csv')\n",
    "\n",
    "train_data         = pd.read_csv(\"C:/Users/KWABENABOATENG/Desktop/AZUBI AFRICA/AZUBI CAPSTONE/AZUBI-CAPSTONE-PROJECT/SampleSubmission.csv\")\n",
    "test_data          = pd.read_csv(\"C:/Users/KWABENABOATENG/Desktop/AZUBI AFRICA/AZUBI CAPSTONE/AZUBI-CAPSTONE-PROJECT/Test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "target_column_name = ['income_above_limit']\n",
    "\n",
    "########## The target column to be used for training \n",
    "target_column      = train_data[target_column_name]\n",
    "\n",
    "########## Since ID is a unique identifier, it must be dropped \n",
    "Cols2drop          = ['ID']\n",
    "\n",
    "\n",
    "######### Feature set corresponding to train and test data\n",
    "train_df           = train_data.drop(Cols2drop+target_column_name,axis=1)\n",
    "test_df            = test_data.drop(Cols2drop,axis=1)\n",
    "\n",
    "print(colored(f'The shape of train data is    {train_df.shape}     ','green',attrs=['bold']))\n",
    "\n",
    "print(colored(f'The shape of target column is {target_column.shape}','green',attrs=['bold']))\n",
    "\n",
    "print(colored(f'The shape of test data is     {test_df.shape}      ','blue',attrs=['bold']))\n",
    "\n",
    "print('------------------------------------------------------------------------------')\n",
    "print(colored('The train data looks like below :- \\n','green'))\n",
    "display(train_df.head(5))\n",
    "\n",
    "print('------------------------------------------------------------------------------')\n",
    "print(colored('The test data looks like below :- \\n','blue'))\n",
    "display(test_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3eHwsyh73-0",
    "outputId": "4144b00e-f95d-48ec-f50e-f52cd1282a3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KWABENABOATENG\\AppData\\Local\\Temp\\ipykernel_6380\\822895601.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_column['income_above_limit'] = target_column['income_above_limit'].map({'Above limit':1,'Below limit':0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Encoding the target column \n",
    "\n",
    "target_column['income_above_limit'] = target_column['income_above_limit'].map({'Above limit':1,'Below limit':0})\n",
    "target_column['income_above_limit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssWWATyLYQEr"
   },
   "source": [
    "<b>Class imbalance </b> <br>\n",
    "\n",
    "\n",
    "We will be seeing the class imbalance using value_counts() method of pandas dataframe and use histogram to plot the imbalances\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "ORYzhnJUXd2p",
    "outputId": "4539bb67-ad4b-4cb6-abb6-58af2c53df60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class Imbalance in the data is given below\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "income_above_limit\n",
       "1    89786\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "\n",
      "The class imbalance in terms of percentage is given below \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "income_above_limit\n",
       "1    1.0\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['Percentage', 'proportion'] but received: Target_values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m pct_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome_above_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget_values\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome_above_limit\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentage\u001b[39m\u001b[38;5;124m'\u001b[39m},axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpct_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPercentage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass imbalance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\express\\_chart_types.py:373\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(data_frame, x, y, color, pattern_shape, facet_row, facet_col, facet_col_wrap, facet_row_spacing, facet_col_spacing, hover_name, hover_data, custom_data, text, base, error_x, error_x_minus, error_y, error_y_minus, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, pattern_shape_sequence, pattern_shape_map, range_color, color_continuous_midpoint, opacity, orientation, barmode, log_x, log_y, range_x, range_y, text_auto, title, template, width, height)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m    326\u001b[0m     data_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    327\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    In a bar plot, each row of `data_frame` is represented as a rectangular\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    mark.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrace_patch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtextposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayout_patch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbarmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbarmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\express\\_core.py:1996\u001b[0m, in \u001b[0;36mmake_figure\u001b[1;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[0;32m   1993\u001b[0m layout_patch \u001b[38;5;241m=\u001b[39m layout_patch \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m   1994\u001b[0m apply_default_cascade(args)\n\u001b[1;32m-> 1996\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constructor \u001b[38;5;129;01min\u001b[39;00m [go\u001b[38;5;241m.\u001b[39mTreemap, go\u001b[38;5;241m.\u001b[39mSunburst, go\u001b[38;5;241m.\u001b[39mIcicle] \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1998\u001b[0m     args \u001b[38;5;241m=\u001b[39m process_dataframe_hierarchy(args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\express\\_core.py:1409\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[1;34m(args, constructor)\u001b[0m\n\u001b[0;32m   1406\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;66;03m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m df_output, wide_id_vars \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_args_into_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwide_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_name\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;66;03m# now that `df_output` exists and `args` contains only references, we complete\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;66;03m# the special-case and wide-mode handling by further rewriting args and/or mutating\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;66;03m# df_output\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m count_name \u001b[38;5;241m=\u001b[39m _escape_col_name(df_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, [var_name, value_name])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\express\\_core.py:1208\u001b[0m, in \u001b[0;36mprocess_args_into_dataframe\u001b[1;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m argument \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1207\u001b[0m             err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m To use the index, pass it in directly as `df.index`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m length \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_input[argument]) \u001b[38;5;241m!=\u001b[39m length:\n\u001b[0;32m   1210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arguments should have the same length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of column argument `df[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]` is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, whereas the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         )\n\u001b[0;32m   1220\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['Percentage', 'proportion'] but received: Target_values"
     ]
    }
   ],
   "source": [
    "print('The class Imbalance in the data is given below')\n",
    "display(train_data['income_above_limit'].value_counts())\n",
    "print('---------------------------------------------------------------\\n')\n",
    "print('The class imbalance in terms of percentage is given below ')\n",
    "display(train_data['income_above_limit'].value_counts(normalize=True))\n",
    "print('----------------------------------------------------------------\\n')\n",
    "pct_df = pd.DataFrame(train_data['income_above_limit'].value_counts(normalize=True)).reset_index().rename({'index':'Target_values','income_above_limit':'Percentage'},axis=1)\n",
    "fig = px.bar(pct_df,x='Target_values',y='Percentage', height=400,width = 400,title='class imbalance')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdXCqdVpZO5h"
   },
   "source": [
    "Clearly we have a highly imbalanced dataset available with us and hence we need to perform steps to mitigate the imbalance accordingly. The following methods could be used:- \n",
    "1. Downsample the majority class (Here majority class is 'Below limit') \n",
    "2. Upsample the minority class (Here, minority class is 'Above limit') \n",
    "3. Use class weights while performing model development <br>\n",
    "Reference : https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExK0qe-_bjWg"
   },
   "source": [
    "<b> NaN value analysis </b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1HVJeYKXd5R"
   },
   "outputs": [],
   "source": [
    "def nan_value_plot(df):\n",
    "    nan_dict  = {}\n",
    "    for cols in df.columns:\n",
    "        nan_dict[cols] = df[cols].isna().sum()/df.shape[0]\n",
    "    nan_pct_df = pd.DataFrame.from_dict(nan_dict,orient='index').reset_index().rename({'index':'Columns',0:'NaN_pct'},axis=1)\n",
    "    fig = px.bar(nan_pct_df,x='Columns',y='NaN_pct', height=400,width = 400,title='NaN value percentage in each column')\n",
    "    fig.update_layout(\n",
    "                        xaxis = dict(\n",
    "                        tickfont = dict(size=5)))\n",
    "    fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "id": "xqpPz5N_Xd8C",
    "outputId": "a68b45a5-0294-451a-97ed-a1e841d7628c"
   },
   "outputs": [],
   "source": [
    "print(colored('We see the distribution of NaN values in train data as below','green',attrs=['bold']))\n",
    "nan_value_plot(train_df)\n",
    "\n",
    "print('-------------------------------------------------------------------------------------------------')\n",
    "print('\\n')\n",
    "print(colored('We see the distribution of NaN values in test data as below','blue',attrs=['bold']))\n",
    "nan_value_plot(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfUoDAEedW8b"
   },
   "source": [
    "<b> Comments:- </b>\n",
    "* There are columns with extremely high proportion of NaN values, we may drop them. \n",
    "* There are columns with NaN values that can be handled easily using imputations with mean, median (in case of numerical) or mode(in case of categorical) \n",
    "* Use Models like LightGBM, CatBoost or XGBoost that handles the NaN values implicitly while model training. \n",
    "* Observe that the proportion of NaN value distribution is same in train and test and select NaN value handling techniques accordingly. \n",
    "* Be creative 🧠 (but also be logical 😉) !!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjzVdsKQexpj"
   },
   "source": [
    "I will personally drop all the columns where the proportion of NaN values is above 80% and proceed with columns/features that are left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zdzU47_vXd_B"
   },
   "outputs": [],
   "source": [
    "nan_cols_drop  = []\n",
    "for cols in test_df.columns:\n",
    "    if test_df[cols].isna().sum()/test_df.shape[0] >0.8:\n",
    "        nan_cols_drop.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ekvv9En1XeCC",
    "outputId": "b52ed7c8-fc69-4527-a8d0-6c0817da9959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWe will drop the following columns from both train and test data: \u001b[0m\n",
      "['education_institute', 'unemployment_reason', 'is_labor_union', 'veterans_admin_questionnaire', 'old_residence_reg', 'old_residence_state']\n"
     ]
    }
   ],
   "source": [
    "print(colored(f'We will drop the following columns from both train and test data: ','yellow',attrs=['bold']))\n",
    "print(nan_cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftntkr3MXeFh",
    "outputId": "27c3890f-a0ef-4811-a585-fa6c41a74885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train and test data before dropping columns with high proportion of NaN values is - \n",
      "\u001b[1m\u001b[32mThe shape of train data is    (89786, 0)     \u001b[0m\n",
      "\u001b[1m\u001b[32mThe shape of target column is (89786, 1)\u001b[0m\n",
      "\u001b[1m\u001b[34mThe shape of test data is     (89786, 41)      \u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['education_institute', 'unemployment_reason', 'is_labor_union', 'veterans_admin_questionnaire', 'old_residence_reg', 'old_residence_state'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe shape of target column is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m,attrs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(colored(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe shape of test data is     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m      \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,attrs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m----> 8\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnan_cols_drop\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m test_df  \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mdrop(nan_cols_drop,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['education_institute', 'unemployment_reason', 'is_labor_union', 'veterans_admin_questionnaire', 'old_residence_reg', 'old_residence_state'] not found in axis\""
     ]
    }
   ],
   "source": [
    "print('The shape of train and test data before dropping columns with high proportion of NaN values is - ')\n",
    "print(colored(f'The shape of train data is    {train_df.shape}     ','green',attrs=['bold']))\n",
    "\n",
    "print(colored(f'The shape of target column is {target_column.shape}','green',attrs=['bold']))\n",
    "\n",
    "print(colored(f'The shape of test data is     {test_df.shape}      ','blue',attrs=['bold']))\n",
    "\n",
    "train_df = train_df.drop(nan_cols_drop,axis=1)\n",
    "test_df  = test_df.drop(nan_cols_drop,axis=1)\n",
    "\n",
    "print('---------------------------------------------------------------------------------------------------')\n",
    "print('The shape of train and test data after dropping columns with high proportion of NaN values is - ')\n",
    "print(colored(f'The shape of train data is    {train_df.shape}     ','green',attrs=['bold']))\n",
    "\n",
    "print(colored(f'The shape of target column is {target_column.shape}','green',attrs=['bold']))\n",
    "\n",
    "print(colored(f'The shape of test data is     {test_df.shape}      ','blue',attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLZXfb8VgOKH"
   },
   "source": [
    "### Simple Baseline Validation strategy \n",
    "\n",
    "We will now do an 80-20 split of train data provided. As discussed previously, the participants are free to use the validation strategy of their own choice. \n",
    "\n",
    "Points to consider while selecting a validation strategy:\n",
    "* Make sure the model is not overfitting on train data. \n",
    "* CV score and leaderboard scores are in sync. \n",
    "* Stable validation strategy when using K Folds etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knl0lYHRXeQZ"
   },
   "outputs": [],
   "source": [
    "train, X_test, train_y, y_test = train_test_split(train_df, target_column, test_size=0.2, random_state=42,stratify=target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaWJ4WnPhlvT"
   },
   "source": [
    "### Model development 🤖 💻 🤖\n",
    "\n",
    "We will be straight away using a CatBoost model for training because it handles categorical features well, can implicitly handle NaN values, and can give a quick baseline (with minimal preprocessing) which can be used as a benchmark to be improved upon. \n",
    "\n",
    "<br>\n",
    "\n",
    "In the below steps, we will convert all the categorical columns to string datatype and capture the indices where string datatype is present which will then be used as an input for the CatBoost Classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-Q9dG7zjAvj"
   },
   "outputs": [],
   "source": [
    "cat_cols_index = np.where(train_df.dtypes=='object')[0]\n",
    "for i in range(len(train_df.columns)):\n",
    "    if i in cat_cols_index:\n",
    "        train[train_df.columns[i]]   = train[train_df.columns[i]].astype(str)\n",
    "        X_test[train_df.columns[i]]  = X_test[train_df.columns[i]].astype(str)\n",
    "        test_df[train_df.columns[i]] = test_df[train_df.columns[i]].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mbDEel07XeWx",
    "outputId": "5ab58a61-0952-4a04-cd77-40cd7e353410"
   },
   "outputs": [],
   "source": [
    "model           = CatBoostClassifier(random_state=42,n_estimators =50 )\n",
    "_               = model.fit(train,train_y,cat_features= cat_cols_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eojVwf4_zxY0"
   },
   "source": [
    "Parameter tuning tips for CatBoost:\n",
    "\n",
    "👓 Do focus on parameters like n_estimators, max_depth, reg_lambda, reg_alpha, scale_pos_weight, learning_rate and explore other parameters from the link : https://catboost.ai/en/docs/references/training-parameters/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6uH4m5uk7kD",
    "outputId": "37665c64-3c53-474e-8a0b-d0f532037d7c"
   },
   "outputs": [],
   "source": [
    "acc_valid = accuracy_score(model.predict(X_test),y_test)\n",
    "\n",
    "print(colored(f'The accuracy attained on the validation set is {acc_valid}','green',attrs=['bold']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HH9qJm_wnnnS"
   },
   "source": [
    "We got a good enough accuracy but is our model really performing that good ?? 🤔\n",
    "\n",
    "👓 Consider the class imbalance of the data given with respect to the metric assigned. We can get 94% accuracy just by classifying everything as 'Below limit' but that will mean that we must get an accuracy above 94% to ensure the models are learning properly. 👓 \n",
    "\n",
    "🔭 Let's investigate the classification report for both train and validation data and see how good the baseline is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jlXsgvgnZZp",
    "outputId": "923d6976-d4fe-42ae-d7b3-1e954c05d5aa"
   },
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print('The classification report only on the validation data is below-')\n",
    "print(colored(classification_report(y_test, model.predict(X_test)),'blue',attrs=['bold']))\n",
    "\n",
    "print('The classification report only on the train data is below-')\n",
    "print(colored(classification_report(train_y, model.predict(train)),'green',attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgzpbMFTn7ir"
   },
   "source": [
    "The performance of our minority class in terms of precision and recall is too low. Hence our F1 score is also very low. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WT5MfS46mDs"
   },
   "source": [
    "### A little hack \n",
    "\n",
    "Let's do a small hack though 🤓 🤓 🤓\n",
    "\n",
    "We can use probability based thresholds and see how performance improves. We will select a lower threshold for class label 1.\n",
    "The default threshold is 0.5 which means that if the probability of 1 is above 0.5, then the predicted class is 1 else it is 0.\n",
    "\n",
    "<br>\n",
    "\n",
    "We will lower the threshold to 0.4 and say that if the probability of class being 1 is above 0.4, then we can classify it as 1 and if it is less than 0.4, then it will be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnoBiaJL7D40",
    "outputId": "d009f5c7-f59d-4652-e9fe-1f289d671146"
   },
   "outputs": [],
   "source": [
    "thresh     = 0.4\n",
    "train_pred = np.where(model.predict_proba(train)[:,1]>thresh,1,0)\n",
    "test_pred  = np.where(model.predict_proba(X_test)[:,1]>thresh,1,0)\n",
    "\n",
    "print('\\n')\n",
    "print('The classification report only on the validation data is below-')\n",
    "print(colored(classification_report(y_test,test_pred),'blue',attrs=['bold']))\n",
    "\n",
    "print('The classification report only on the train data is below-')\n",
    "print(colored(classification_report(train_y, train_pred),'green',attrs=['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPPHhkd5-BJj"
   },
   "source": [
    "We do see some improvement in the performance because the f1 score on our validation data moved from 0.58 to 0.61. \n",
    "For more information about how the threshold is selected, please follow [ROC Curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) of sklearn and in general how ROC curve works 📚 📚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6yifLIyoEQb"
   },
   "source": [
    "### Submission Time 🎉\n",
    "\n",
    "We will now predict on the test data given and see what score we get on leaderboard. \n",
    "\n",
    "We will now download the file \"Sample_submission_1.csv\" and submit it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFlITBHen2HZ",
    "outputId": "0c86cee4-122c-45c0-9746-20683bb4d474"
   },
   "outputs": [],
   "source": [
    "subdf                       = pd.read_csv('/content/SampleSubmission.csv')\n",
    "subdf['income_above_limit'] = model.predict(test_df)\n",
    "subdf.to_csv('Sample_submission_1.csv',index=False)\n",
    "subdf['income_above_limit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKBJLRQoqZza"
   },
   "source": [
    "How to get better scores:\n",
    "1. Feature engineering is the key. Refer to the variable dictionary and create meaningful features which can boost the score\n",
    "2. Try out different models and categorical data preprocessing (read about categorical encoding) because a lot of features are categorical. \n",
    "3. Feature selection with feature importance \n",
    "4. Keep a check on classification report to observe overfitting and underfitting and select appropriate hyper-parameters to tune.\n",
    "5. Suitable probability threshold selection as shown above. \n",
    "6. Be creative while selecting validation split \n",
    "For example:- Use Stratified K folds, grouped K folds, repeated stratified k folds, train test split with stratification etc \n",
    "7. Ensemble multiple models to get a stable prediction. \n",
    "8. Be creative and may the best model win 🏆 🏆 🏆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XF8r3ySkA5iP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
